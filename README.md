# avocado

## Checklist

- [x] Add route to retrieve jobs via CURL (standard get)
- [ ] Add relative link to worker/README.md where appropriate
- [x] Fix worker date serialization bug
- [x] Add instructions for retrieving images from plot jobs
- [ ] Add dataset overview
- [x] Catch invalid IDs on image, get routes

## Usage

Our system supports a variety of actions (jobs) which interact with and run analysis on our dataset.  All jobs must be submitted to our API where they are queued for processing by worker nodes.

The following job types are supported:

* Insert
* Query
* Update
* Delete
* Plot
* Summary

### Preferred Method: Web Application

Our web application can be accessed at https://isp-proxy.tacc.utexas.edu/phart/index.

### Alternate Method: Interact directly with our API

If you prefer to submit jobs in raw JSON format, you can do so using the `raw_jobs` route.  See `avocado/worker/README.md` for proper job formatting and examples.

Jobs can be sent via POST request using curl or a program like Postman.

#### Using Curl

Since the job structure can be complex, it is easiest to save the JSON to a file and use curl to POST from the file.

First, create a new file `job.json` and add the job details as described in `avocado/worker/README.md`:

```json
{
    "job_type": "query",
    "status": "submitted",
    "cols": ["id", "week", "volume", "price"],
    "params": [{
        "column": "year",
        "type": "equals",
        "value": 2018
        },
        {
        "column": "week_id",
        "type": "equals",
        "value": 3
        }]
}
```

Next, use CURL to send a POST request.

```
[avocado]$ curl -X POST -H "content-type: application/json" -d @data.json https://isp-proxy.tacc.utexas.edu/phart/raw_jobs
{
    "job_type": "query",
    "status": "submitted",
    "cols": [
        "id",
        "week",
        "volume",
        "price"
    ],
    "params": [
        {
            "column": "year",
            "type": "equals",
            "value": 2018
        },
        {
            "column": "week_id",
            "type": "equals",
            "value": 3
        }
    ],
    "id": "3479bc65-1484-4316-8efa-de33e63ea961",
    "submitted": "2021-05-05 20:04:17.336567"
}
```

To access the image generated by a plot job, you will need the job id assigned when your job was submitted.  You can download the image using `wget`.

```bash
[avocado]$ wget https://isp-proxy.tacc.utexas.edu/phart/download/<jobid>
```

## Deployment Instructions

### Production Deployment Instructions (Kubernetes)

Section in progress...

### Test Deployment Instructions (docker-compose)

For rapid testing and development, the project can be launched using docker-compose.

Use the `-d` flag to run in the daemon mode and the `--build` flag to rebuild the containers on launch (optional).

```
docker-compose up -d --build
...
Starting avocado_redis_1    ... done
Starting avocado_postgres_1 ... done
Starting avocado_api_1      ... done
Starting avocado_worker_1   ... done
```

To launch multiple workers, add `--scale worker={num_workers}`

```
docker-compose up -d --scale worker=3
Starting avocado_redis_1    ... done
Starting avocado_postgres_1 ... done
Starting avocado_api_1      ... done
Starting avocado_worker_1   ... done
Starting avocado_worker_2   ... done
...
```
